{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313e117d",
   "metadata": {},
   "source": [
    "# Rice Classification — Engineered Notebook (v3, dtype‑safe)\n",
    "\n",
    "**Fix for your error**: some environments load CSV numeric columns as `object`, so the numeric selector\n",
    "picked **0 columns**. This version **coerces all feature columns to numeric** with `pd.to_numeric(errors=\"coerce\")`\n",
    "*before* building the pipeline. Everything else（CV、GridSearch、评估、持久化）保持不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import joblib, sklearn, matplotlib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(0)\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"sklearn:\", sklearn.__version__, \"| pandas:\", pd.__version__, \"| matplotlib:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b287966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_file():\n",
    "    for p in [Path(\"../data/rice-final2.csv\"), Path(\"./data/rice-final2.csv\"), Path(\"rice-final2.csv\")]:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Could not find rice-final2.csv in ../data, ./data or current dir.\")\n",
    "\n",
    "data_path = find_data_file()\n",
    "print(\"Using dataset:\", data_path.resolve())\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "print(\"\\nRaw dtypes:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DTYPE FIX: coerce features to numeric ---\n",
    "assert \"class\" in df.columns, \"Missing target column 'class'\"\n",
    "label_map = {\"class1\": 0, \"class2\": 1}\n",
    "y = df[\"class\"].map(label_map).astype(int).values\n",
    "\n",
    "X = df.drop(columns=[\"class\"]).copy()\n",
    "for c in X.columns:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nAfter coercion dtypes:\\n\", X.dtypes)\n",
    "numeric_features = list(X.columns)\n",
    "assert len(numeric_features) > 0, \"No numeric features after coercion.\"\n",
    "print(f\"Numeric features: {len(numeric_features)} ->\", numeric_features)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=0\n",
    ")\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b473fe",
   "metadata": {},
   "source": [
    "## Baselines — 10‑Fold Stratified CV (no tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", make_pipeline(SimpleImputer(strategy=\"mean\"), MinMaxScaler()), numeric_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=0),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"DecisionTree(entropy)\": DecisionTreeClassifier(criterion=\"entropy\", random_state=0),\n",
    "    \"KNN(k=5,p=1)\": KNeighborsClassifier(n_neighbors=5, p=1),\n",
    "    \"SVM(RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=0),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=0),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "rows = []\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"pre\", preprocess), (\"clf\", clf)])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "    rows.append((name, scores.mean(), scores.std()))\n",
    "\n",
    "import pandas as pd\n",
    "cv_table = pd.DataFrame(rows, columns=[\"Model\", \"CV_Acc_Mean\", \"CV_Acc_Std\"]).sort_values(\"CV_Acc_Mean\", ascending=False)\n",
    "cv_table.reset_index(drop=True, inplace=True)\n",
    "cv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480df29",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (SVM & RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc804839",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = Pipeline([(\"pre\", preprocess), (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=0))])\n",
    "param_svm = {\"clf__C\": [0.5, 1, 2, 5], \"clf__gamma\": [\"scale\", 0.5, 1, 2]}\n",
    "\n",
    "pipe_rf = Pipeline([(\"pre\", preprocess), (\"clf\", RandomForestClassifier(random_state=0))])\n",
    "param_rf = {\"clf__n_estimators\": [50, 100, 200],\n",
    "            \"clf__max_leaf_nodes\": [None, 12, 24],\n",
    "            \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
    "            \"clf__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "searches = {\"SVM(RBF)\": (pipe_svm, param_svm), \"RandomForest\": (pipe_rf, param_rf)}\n",
    "best_models = {}\n",
    "for name, (pipe, param) in searches.items():\n",
    "    gs = GridSearchCV(pipe, param_grid=param, scoring=\"accuracy\", cv=cv, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_models[name] = gs\n",
    "    print(f\"[{name}] Best params:\", gs.best_params_, \"CV Best:\", round(gs.best_score_, 4))\n",
    "\n",
    "name_best = max(best_models, key=lambda k: best_models[k].best_score_)\n",
    "gs_best = best_models[name_best]\n",
    "print(\"\\n=> Selected best by CV:\", name_best)\n",
    "\n",
    "y_pred = gs_best.predict(X_test)\n",
    "if hasattr(gs_best, \"predict_proba\"):\n",
    "    y_score = gs_best.predict_proba(X_test)[:, 1]\n",
    "else:\n",
    "    y_score = gs_best.decision_function(X_test)\n",
    "\n",
    "print(\"Test accuracy:\", round((y_pred == y_test).mean(), 4))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "test_metrics = {\n",
    "    \"model\": name_best,\n",
    "    \"test_accuracy\": float(np.mean(y_pred == y_test)),\n",
    "    \"test_f1_macro\": float(f1_score(y_test, y_pred, average=\"macro\")),\n",
    "    \"test_f1_weighted\": float(f1_score(y_test, y_pred, average=\"weighted\")),\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_score)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, y_score)),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef80de7",
   "metadata": {},
   "source": [
    "## Plots — Confusion Matrix, ROC, PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig = plt.figure()\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot(values_format=\"d\")\n",
    "plt.title(f\"Confusion Matrix — {name_best}\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc(fpr, tpr):.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {name_best}\"); plt.legend(); plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f\"AP={average_precision_score(y_test, y_score):.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {name_best}\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4075c",
   "metadata": {},
   "source": [
    "## Save model & quick inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_dir = Path(\"../artifacts\") if Path.cwd().name == \"notebooks\" else Path(\"./artifacts\")\n",
    "art_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = art_dir / f\"best_model_{name_best.replace(' ','_').replace('(','').replace(')','')}.joblib\"\n",
    "joblib.dump(gs_best.best_estimator_, model_path)\n",
    "print(\"Saved:\", model_path.resolve())\n",
    "\n",
    "loaded = joblib.load(model_path)\n",
    "demo = pd.DataFrame(X_test, columns=X.columns).head(5)\n",
    "print(\"Demo preds:\", loaded.predict(demo).tolist())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
